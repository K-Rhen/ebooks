\documentclass{vivid_layout}

% \makeprint is for printing and trimming on paper, w/crop marks.
% \makeprint

%\usepackage{tikz}
%\usetikzlibrary{datavisualization}
%\usetikzlibrary{datavisualization.formats.functions}

%% Required to build cover page
\title{Everything You Need To Know About}{Scalability}
\date{\today}
\cover{scalability/cover}

%% Required to build "Meet the Author"
\author{Baron Schwartz}{img/baron}

%% Required image for "About VividCortex"
\aboutvc{img/presenter}

%% Required resource info
\resourceleft%
	{The Strategic IT Manager's Guide To Building A Scalable DBA Team}
	{}
	{img/scalable-dba-team}
	{https://www.vividcortex.com/resources/building-scalable-dba-team/}
\resourceright%
	{Case Study: SendGrid}
	{VividCortex has been instrumental in finding issues. It's the go-to solution for seeing what's happening in production systems.}
	{img/sendgrid-thumbnail}
	{https://www.vividcortex.com/resources/case-studies/sendgrid/}

\begin{document}
\maketitle		% Build the cover page
\begin{bio}		% Biographical info for "Meet the Author"
Baron is well-known for his contributions to the MySQL, PostgreSQL, and Oracle communities. Baron has helped build and optimize database systems for some of the largest Internet properties. He has written several books, including O'Reilly's best-selling High Performance MySQL. Prior to founding VividCortex, Baron managed consulting, support, training, and software engineering at Percona. He has a CS degree from the University of Virginia.
\end{bio}
\tableofcontents	% Build the table of contents

\section{Introduction}

Making systems big, fast, and efficient is one of the most interesting things
I've done as a software engineer. It's a great feeling when you fix a
bottleneck, and get dramatically improved performance at scale. You suddenly
realize how wasteful your systems were before the improvement. It's really
satisfying when it all comes together and you get great results.

I've participated in lots of projects that have produced those kinds of results.
It's no coincidence that the best results came from the projects where the most
disciplined analysis was performed up front. Like performance optimization,
scalability optimization can be a real mystery unless you have an accurate model
of how the world works, good measurements of how your systems are performing,
and the ability to identify the problem and its likely fix with high certainty.

What's even better than fixing problems with scalability is the ability to
design systems (and organizations) that scale in the first place. This is worth
its weight in gold.

Scalability is quite a scientific topic, but it doesn't need to be mysterious.
It's true that queueing theory is intimately involved, and queueing is
complicated and unintuitive. But what's really cool is that scalability,
correctly understood, is quite straightforward despite the complexity of what's
going on behind the scenes.

I wrote this book to help you understand the simple, but profoundly
powerful, truths about scalability. I also wanted to help you understand the
connections between scalability and other disciplines, such as performance
optimization or the study of queueing. My hope is that this book is as
transformational and rewarding for you as the process of learning these concepts
has been for me.

\section{What is Scalability?}

Scalability is ambiguous for many people---a vague term often tossed about in
conference presentations, for example. It's often used in ways confusingly
similar to performance, efficiency, capacity, availability, and many other terms
related to making things big and fast.

Wikipedia's definition of scalability, borrowed from a 2000 paper by Andr\'e B.
Bondi, is ``the capability of a system, network, or process to
handle a growing amount of work, or its potential to be enlarged in order to
accommodate that growth.'' This isn't wrong, but it's still a bit informal, and
this ebook needs a more formal definition.

Dr. Neil J. Gunther provides one such definition: scalability is a {\itshape
function}. I read his books and heard him speak, but it was still a year or so
before that sunk in for me. {\itshape Scalability can be defined as a
mathematical function}, a relationship between independent and dependent
variables (input and output). This is the type of formal definition we need to
model and analyze scalability.

The most important part of understanding such a scalability model is choosing
the correct variables in order to analyze the way systems really operate.
Bondi's definition provides a good clue: {\itshape work} is the driving factor
of scalability. Useful ways to think about work include, to mention a few,

\begin{itemize}
\item Units of work (requests).
\item The rate of requests over time (arrival rate).
\item The number of units of work in a system at a time (concurrency).
\item The number of customers or users sending requests.
\end{itemize}

Each of these can play sensible roles in the scalability function, depending on
how you view it. For example, it's quite common to configure the number of
threads a benchmark runs to send requests to a database. The benchmark usually
sends requests as fast as possible, assuming zero think time, so the arrival
rate is related to, but not strictly controlled by,\footnote{Because it is
determined by how quickly the database finishes each request.} the benchmark
configuration.

You could say that the amount of work requested is the input to the benchmark's
scalability function, and the completion rate is the output.

In another scenario, you might vary the number of CPUs for the system under test
(SUT) while holding constant the load per CPU, or if it's a clustered database,
vary the cluster size and hold constant the load per node. In this case, the
independent variable is the system size and the dependent variable is the
completion rate.

In most cases I've analyzed, either size or load are the sensible
independent variables for the scalability function. So for the purposes of this
book, we'll consider scalability to be {\itshape a function of size or load}.
The dependent variable will be the rate at which the system can complete work,
or {\itshape throughput}. The hope is that the system should produce more work
as size or load grow, so it should be an increasing function.
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/size-vs-load}
\end{center}

For those who are like me and need extra emphasis, I'll repeat that this is a
mathematical function, with size or load on the $X$ axis, and throughput on the
$Y$ axis. We'll make this more precise later.

\section{Linear Scalability: The Holy Grail}

In my experience, never was a marketechture slide deck created that mentions
scalability without also including the word ``linear.'' But as you might expect,
``linear scalability'' is not what people would have you believe.
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/inigo}
\end{center}

Hand-waving claims of linear scaling usually coincide with vague definitions
of scalability, and people who know a lot about scalability rarely say the word
``linear.'' Here are a few of the misdefinitions of linear scalability I've heard:

\begin{itemize}
\item A web architect at a conference said, ``I designed our system to be
shared-nothing so it would be linearly scalable.'' He meant there was no
single resource or system imposing a hard upper limit on how many servers could
be added to the system. But he didn't really know whether his system actually
scaled linearly.
\item A technical evangelist giving a presentation about a clustered database
said, ``adding a node to the cluster adds a predictable amount of capacity.''
Predictable isn't the same as linear.
\item A sales presentation for another clustered database said the database
``scales linearly, with a linearity factor of 97\%,'' meaning that each
additional node increases the system's capacity by 0.97 times the amount the
previous node added. That's a curve, not a line.  (Later you'll learn how to
instantly determine the asymptotic upper bound on such a system's total
capacity.)
\end{itemize}

This may seem like a pointless rant, but it's actually important if you want to
be able to design and improve highly scalable systems.

Spotting bogus linearity claims is fun. Here are some ways
``benchmarketing'' makes systems appear linear:

\begin{itemize}
\item Show graphs without numbers, so readers can't do the math.
\item Show graphs with nonlinear axes.
\item Begin the axes, especially the $Y$ axis, at a nonzero value.
\end{itemize}

Here is a real example, redacted to protect the not-so-innocent, that employs
some of these tricks.
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/voltdb1}
\end{center}
Looks pretty linear, doesn't it? Yet if you do the math, it's nowhere near
linear.  It's an optical illusion, because the $X$ axis begins around
1.45 instead of zero, and the $Y$ axis starts at 100000, so you can't tell that
the chart isn't going to intersect the origin if you extend it downwards.

{\bfseries The real test of linearity is whether the transactions per second per
node remains constant as the node count increases}. The chart's original source
mentioned that throughput increased from ``182k transactions per second for 3
nodes to 449k for 12 nodes.'' The math is easy: the system achieves 60700
transactions per second per node at 3 nodes, but only 37400 at 12 nodes, which
represents a {\itshape 39\% drop in throughput} versus linear scalability.  If
it actually scaled linearly, it would achieve 728k transactions per second at 12
nodes.

Linear means linear, folks! And seemingly small amounts of nonlinearity really
matter, as you'll see later, because small sublinear effects grow very quickly
at larger scale.\footnote{In fact, they grow---wait for it---nonlinearly!}

\section{Why Systems Scale Sublinearly}

Linear scalability is the ideal, yet despite the claims, systems that actually
scale linearly are rare.  It's very useful to understand the reasons for this,
because a correct understanding of scalability, and the reasons and sources of
sublinear scaling, is the key to building more scalable systems.  That's why
it's really important to be a linearity skeptic.  It's not just being pedantic.

The best way to think about linearity is as a ratio of the system's performance
at a size of 1, if possible. Neil Gunther calls this the {\itshape efficiency}.
If a system produces 1800 transactions per second with 1 node, then ideally 4
nodes produce 7200 transactions per second. That would be 100\% efficient. If
the system loses a bit of efficiency with each node and 4 nodes produce, say,
5180 TPS, then the 4-node system is only 72\% efficient:
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/linear2}
\end{center}
If you do this math, you'll often be surprised at how large the loss of
efficiency is.  Graphs can be deceptive, but the numbers are quite
clear.\footnote{Drawing a linear scaling line on the graph helps, too. Without
that line, the eye tends to see the graph as more linear than it really is, and
the loss of efficiency becomes less obvious.}


In the real world there's almost always some loss of efficiency, and if you can
figure out why, you may be able to fix it. In fact, you've probably noticed that
real systems tend not only to fall behind linear scalability a bit, but actually
exhibit {\itshape retrograde} scalability at some point:
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/linear3}
\end{center}
This is quite common in the real world---you scale things up and at some point
your system starts going backwards and {\itshape losing} performance, instead of
just gaining more and more slowly. In the MySQL 5.0 days, for example, it was
common to see people upgrading from 4-core servers to 8-core servers and losing
performance.

Why does this happen? Why don't systems scale linearly, and why do they
sometimes show retrograde scalability?

According to Neil Gunther, there are two reasons: {\bfseries serialization} and
{\bfseries crosstalk}. Serialization degrades scalability because parts of the
work can't be parallelized, so speedup is limited. Crosstalk introduces a
fast-growing coherency delay as workers (threads, CPUs, etc) block on shared
mutable state and communication mechanisms. We'll explore these effects in the
next section.

\section{The Universal Scalability Law}

Neil Gunther's Universal Scalability Law (USL) provides a formal definition of
scalability,\footnote{Neil Gunther originally called a slightly different form
of the USL ``superserial,'' and you may encounter this terminology, especially
in older books and papers.} and a conceptual framework for understanding,
evaluating, comparing, and improving scalability. It does this by quantifying
the effects of linear speedup, serialization delay, and coherency delay due to
crosstalk.

Let's see how this works, piece by piece. An ideal system of size 1
achieves some amount $\lambda$ of throughput $X$, in completed requests per
second. Because the system is ideal, the throughput doubles at size $N$=2, and so
on. This is perfect linear scaling:
\[
X(N) = \frac{\lambda N}{1}
\]

The $\lambda$ parameter defines the slope of the line. I call it the {\itshape
coefficient of performance}. It's how fast the system performs in the special
case when there's no serialization or crosstalk penalty.
Here are two ideal systems, with $\lambda$ of 1800 and 800, respectively.
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/ideal-linear}
\end{center}

Note that every linearly scalable system is just as scalable as any other,
regardless of the slope of the line. They have different performance but
identical scalability characteristics: speedup is unlimited. 

Serialization appears in most systems\footnote{Including teams of people.} at
some point, for example as a final stage of assembling the multiple outputs
generated in parallel into a single final result. As parallelization increases,
serialization becomes the limiting factor. This is codified in
\href{https://en.wikipedia.org/wiki/Amdahl\%27s\_law}{Amdahl's Law}, which
states that the maximum speedup possible is the reciprocal of the serial
fraction. We'll add a term to the denominator expressing the serial fraction of
the work, multiplied by $\sigma$, the coefficient of serialization, and now we
have Amdahl's Law:
\[
X(N) = \frac{\lambda N}{1 + \sigma(N-1)}
\]

Serialization creates contention, and a system that is partially serialized will
asymptotically approach a ceiling on speedup. If $\sigma$ is .05, for example,
the speedup approaches 20. Let's see that graphically:
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/amdahl}
\end{center}

Remember the system I mentioned earlier, which a salesperson claimed to have
97\% scalability with each additional node? That's 3\% loss of scalability per
node, so this system will never achieve a speedup factor of more than 33, no
matter how many nodes it has.

The last bit is the crosstalk penalty, also called the consistency or coherency
penalty.\footnote{I call it crosstalk because in my opinion it's the best
description of the pairwise communication that must occur to make distributed
data or other shared resources consistent or coherent.} Crosstalk potentially
happens between each pair of workers in the system (threads, CPUs, servers,
etc).  You probably remember that the number of edges in a fully connected graph
is $n(n-1)$.  We represent the amount of crosstalk with another term, multiplied
by $\kappa$, the coefficient of crosstalk. This is the USL:
\[
X(N) = \frac{\lambda N}{1 + \sigma(N-1) + \kappa N(N-1)}
\]

The crosstalk penalty grows fast. Because it's quadratic,\footnote{The cost of
$n(n-1)$ is $\mathcal{O}(n^2)$. If you're not familiar with it,
\href{https://www.vividcortex.com/blog/2013/10/23/big-o-notation-made-simple/}{this
blog post introduces Big-O notation}.} eventually it grows faster than the
linear speedup of the ideal system we started with, no matter how small $\kappa$
is. That's what makes retrograde scalability happen, as you can see in the
following chart:
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/usl}
\end{center}

That's the Universal Scalability Law in all its glory.  This plot has the same
parameters as the ones I showed before, where a system of size 4 produced only
72\% of its ideal output. That system has 5\% serialization and 2\% crosstalk,
and now that I've plotted it out to size 20 you can see it's embarrassingly
inefficient.  In fact, we should have given up trying to scale this system after
size 6 or so.

This shows visually how much harm a ``small amount'' of nonlinearity can do in
the long run.  Even very small amounts of these damaging coefficients will
create this effect sooner or later (mostly sooner). This is why it's rare to
find clustered systems that scale well beyond a couple dozen nodes or so.
If you'd like to experiment with this interactively, I've made a graph of it at
\href{https://www.desmos.com/calculator/2l0jcjmsxn}{Desmos}.

If you're curious, the USL is based on queueing theory; Neil Gunther proved that
it's equivalent to synchronous repairman queueing. If you're not familiar with
queueing theory, I wrote a highly approachable introduction called
\href{https://www.vividcortex.com/resources/queueing-theory/}{Everything You
Need To Know About Queueing Theory}.

\section{Measuring Scalability}

To recap, at this point we've figured out the right dimensions for a formal model
of scalability that seems to behave as we know real systems behave, and examined
Neil Gunther's USL, which fits that framework well and gives us an equation for
scalability. (Are you excited yet?)

Now what do we do with it?

Great question! It turns out we can do a lot of extremely useful things with the
USL.  Unlike a lot of models of system behavior, this one is actually practical
to apply in the real world. That's the real genius of it, in fact. Not only is
the equation uncomplicated, but the variables it describes are easy to get most
of the time.

I use the USL mostly for modeling system scalability, by working backwards from
observed system behavior and estimating the likely coefficients. To accomplish
this, you need a set of measurements of the system's load or size (usually
concurrency or node count) and the corresponding throughput. Then you {\itshape
fit} the USL to this dataset, using nonlinear least squares regression. This is
a statistical technique that finds the optimal coefficient values in order to
calculate a best-fit line through the measurements. The result is values for
$\lambda$, $\sigma$, and $\kappa$.

If you're reading about the USL in Neil Gunther's books, he takes a different
approach. First, he doesn't use regression to determine $\lambda$, he assumes
that you can measure it in a controlled way at $N=1$. (I've often found that's
not true for me.) Secondly, there are a couple of different forms of the
USL---one for hardware scaling and one for software scaling---which are the same
equation, but with different parameters. I've found the distinction to be
largely academic, although I will talk a bit more about this later.

Examples of systems I've analyzed with the USL include:

\begin{itemize}
\item Black-box analysis of networked software simply by observing and
correlating packet arrivals and departures, looking at the IP addresses, port
numbers, and timestamps. From this I computed the concurrency by averaging the
amount of time the system was busy servicing requests over periods of time. The
throughput was straightforward to get by counting packet departures.
\item MySQL database servers. Some of its \texttt{SHOW STATUS} counters are
essentially equivalent to throughput and concurrency.
\item Linux block devices (disks) by looking at \texttt{/proc/diskstats}, from
which you can get both instantaneous and average concurrency over time deltas,
as well as throughput (number of I/Os completed).
\item Lots and lots---and lots---of benchmark results.
\end{itemize}

I've built a variety of tools to help clean, resample, and analyze the data
before arriving at satisfactory results. Most of them were commandline, though
these days I use R more than anything else. This is an important topic:
you will get dirty data, and that will
make your results less useful. You need to visualize both in scatterplot form as
well as in time-series form and ensure you're working with a relatively
consistent set of data. You can remove individual points or trim the time range
you use, and you may need to experiment with averaging the data over time to get
good results.

As for the R code, I'll give a little bit of a quickstart to show the
soup-to-nuts approach.  You'll save the data into a delimited file, with column
headers \texttt{size} and \texttt{tput}. Then you'll load this into a variable
in R and regress it against the USL.

Here's a complete sample, based on a
\href{https://www.percona.com/docs/wiki/benchmark:cisco:scale:start}{benchmark}
that Vadim Tkachenko ran at Percona:

\begin{verbatim}
size tput
1 955.16
2 1878.91
3 2688.01
4 3548.68
5 4315.54
6 5130.43
7 5931.37
8 6531.08
9 7219.8
10 7867.61
11 8278.71
12 8646.7
13 9047.84
14 9426.55
15 9645.37
16 9897.24
17 10097.6
18 10240.5
19 10532.39
20 10798.52
21 11151.43
22 11518.63
23 11806
24 12089.37
25 12075.41
26 12177.29
27 12211.41
28 12158.93
29 12155.27
30 12118.04
31 12140.4
32 12074.39
\end{verbatim}

Save that data into a file, say, \texttt{benchmark.txt}. Then load it and run the following commands:

\begin{verbatim}
benchmark <- read.csv("/path/to/benchmark.txt", sep="")
usl <- nls(tput ~ lambda*size/(1 + sigma * (size-1) + kappa * size *
   (size-1)), benchmark, start=c(sigma=0.1, kappa=0.01, lambda=1000))
summary(usl)
sigma <- coef(usl)['sigma']
kappa <- coef(usl)['kappa']
lambda <- coef(usl)['lambda']
u=function(x){y=x*lambda/(1+sigma*(x-1)+kappa*x*(x-1))}
plot(u, 0, max(benchmark$size)*2, xlab="Size", ylab="Throughput", lty="dashed")
points(benchmark$size, benchmark$tput)
\end{verbatim}

The results are as follows:
\[
\begin{array}{ll}
			\lambda&995.6486 \\
     \sigma & 0.02671591 \\
			       \kappa & 0.0007690945 \\
\end{array}
\]

Note the extremely small value for $\kappa$ which nonetheless degrades
scalability before $N$ becomes very large. Here's the resulting plot:
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/cisco}
\end{center}

If you're an R user, that's probably all you need to get going. You really
should do more diligence, such as checking the $R^2$ value of the fit. But
instead of doing all this work manually (which you can certainly do if you
want), I suggest trying the
\href{https://cran.r-project.org/web/packages/usl/}{USL package from CRAN}. It
has many features built in, although it does have some limitations.

One final thing: if the $\kappa$ coefficient has a nonzero value, the function
has a maximum. You can find the size of the system at that maximum as follows:
\[
N_{max} = \left \lfloor \sqrt{\frac{1-\sigma}{\kappa}} \right \rfloor
\]

Of course, to find the maximum predicted throughput, you just plug $N_{max}$
into the USL equation itself. Doing so with the coefficients in this example
predicts the system's throughput will increase until $N=35$, which in this case
means 35 threads, and the peak throughput will be 12341 queries per second. It
also found $\lambda$, the throughput at $N=1$, to be 995 QPS, which is close to
the actual value of 955.

It's always interesting to use the USL on a subset of the performance data, such
as the first third or so, to see how well it predicts the higher $N$ values.
This can be quite educational.

Note that you should have at least half a dozen or so data points in order to
get good results in most circumstances. In practice I usually try to capture at
least a dozen for benchmarks, and more---often thousands---when analyzing
systems that aren't in a controlled laboratory setting.

\section{Relating Scalability and Performance}

Throughput and latency are two common measures of performance. Most benchmarks
measure overall system throughput, and claims of performance are almost always
in throughput terms: ``a million transactions per second,'' and so on.
Benchmarks usually define performance as how much work the system can do.

On the other hand, users care mostly about the performance of individual
requests. A user's opinion about your website's performance is based entirely on
how quickly pages load and render.  From this viewpoint, as Cary Millsap says,
{\itshape performance is response time}.

Which view is right? Both. System performance is measured in throughput, and
request performance is measured in latency.

We've seen that the USL can model and forecast how system size affects
throughput. Can it also model latency? Yes, it can when the independent variable
is concurrency, because of a relationship called Little's Law:
\[
N = X R
\]

Little's Law says that the mean number of requests resident in a system is
equal to the throughput times the mean response time. This relationship is
valid for stable systems, in which all requests eventually complete.

It's straightforward to use Little's Law together with the USL and solve for
response time as a function of concurrency.\footnote{ Note that if the number of
nodes is the independent variable, it's a different scenario. Such a benchmark
should hold concurrency per node constant, to load all nodes equally as the
cluster grows.} The result is a quadratic function:
\[
R(N)=\frac{1+\sigma(N-1)+\kappa N(N-1)}{\lambda}
\]

According to the model, response time is related to the square of concurrency.
Here's the same data we saw previously, now inverted and used to predict
response time.
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/cisco-tput}
\end{center}

Be careful not to confuse this chart with another famous ``hockey stick'' chart,
that of response time versus utilization, which is familiar from queueing
theory:
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/hockey}
\end{center}

The difference is that one chart uses utilization as the independent variable,
which ranges only from 0 to 1, whereas the other uses concurrency, which has no
fixed upper limit.

The inverted USL predicts mean response time. If you wanted to, you could
use queueing theory to assess this in a more nuanced way, such as the
probability that any given request needed to wait more than a set amount of
time.

\section{Capacity Planning with the USL}

``How much load can this system sustain?'' is a common question in capacity
planning. The practical purpose is usually something like the following:

\begin{itemize}
\item How soon will the system begin to perform badly as load increases?
\item How many servers will I need for the holidays?
\item Is this system close to a breaking point?
\item Are we overprovisioned? By how much?
\end{itemize}

Capacity planning is often a difficult problem because it's hard to tell what a
system's true capacity is. The USL can be helpful in understanding this, to a
point.

There are conventional ways to determine system capacity, but they're often
difficult, expensive, and don't give results you can really believe in. For
example, you can set up load tests, but it takes a lot of work and time, and the
results are suspect because the workload is always artificial in some
way.

You can also run benchmarks, but most benchmarks are pretty useless for
predicting a system's usable capacity. In addition to being an artificial
workload, they push a system to its maximum throughput and beyond. As I
mentioned, it's rare for benchmarks to be run by people who understand the
importance of latency. But when I do see benchmarks that measure latency
percentiles, the systems almost always perform very badly at their peak
throughput.\footnote{This is a problem with the way benchmarks are usually
designed, in my opinion. I'd really prefer for the benchmark system to be
intelligent enough to back off and reduce pressure on the system under test if
it violates a service level objective (SLO).  Ideally, this is defined as a
quantile, such as 99th percentile latency less than 10ms.  A smart benchmark
would throttle load, eventually finding a longterm stable arrival rate at which
the SUT can consistently perform well.}

Another way I've tried to predict system capacity in the past is with queueing
theory, using the Erlang C formula to predict response time at a given
utilization.  Unfortunately, this requires that you know service times,
which are often impossible to obtain. You can measure total response time, but
that includes waiting time in the queue, so it's not the same thing as the
service time. The utilization is also often deceptive, because the real
utilization of the resources you're trying to measure can be difficult to
measure correctly too. Most people I know consider the Erlang approach to be
difficult to apply.

If load tests, benchmarks, and queueing theory are difficult to use, can the USL
help? Yes, it can.  The USL's point of maximum predicts the system's
maximum throughput, so it's a way to assess a system's capacity.  Because the
USL is a {\itshape model}, it can help you use observed data to predict how a
system will perform under load beyond what you can observe. As a result you can
get a much better idea of how close you are to the system's maximum capacity.

The USL has a few nice properties:

\begin{itemize}
\item It's a ``black box'' technique, which uses data that's usually easy to get.
\item Gathering data and using regression to analyze it is also easy.
\item The USL is a relatively simple model, so people like me can understand the math. 
\item The USL is highly intuitive in comparison to most other approaches.
\end{itemize}

One of the major caveats is that maximum throughput isn't maximum {\itshape
usable} capacity. Again, when the system is at its maximum throughput, response
time is probably terrible, and will be extremely inconsistent. That's why it's
more important to focus on the system's maximum throughput within the
constraints of a service level objective.

Another important thing to realize is that a lot of systems perform worse than
the USL predicts they will, because their degradation in scalability at larger
sizes is more severe than predicted. As a result, I suggest viewing the USL's
prediction as optimistic: ``I won't count on being able to scale this system as
high as the USL predicts I can.''

You can also combine the USL with selected techniques from queueing theory, such
as the Square Root Staffing Rule, to understand how much capacity is needed and
what quality of service it will provide. See the aforementioned
\href{https://www.vividcortex.com/resources/queueing-theory/}{queueing theory
ebook} for more on this topic.

\section{Using the USL to Improve Scalability}

One of the best uses of the USL is to explain {\itshape why} a system doesn't
scale as well as it might. Armed with this knowledge, you know where to look for
bottlenecks, so you might be able to alleviate them and improve the system's
scalability.  With practice, you'll also develop a mindset of scalability,
building intuition about which design decisions can cause serious sublinearity.

An example will help illustrate. A few years ago PayPal published
\href{https://www.paypal-engineering.com/2013/11/22/node-js-at-paypal/}{benchmark
results} of a Java application they rewrote in NodeJS. I analyzed their
benchmark results and
\href{https://www.vividcortex.com/blog/2013/12/09/analysis-of-paypals-node-vs-java-benchmarks/}{wrote} about it on the VividCortex blog.
Here are the plots and the key scalability parameters:
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/paypal}
\end{center}
\[
\begin{array}{lcc}
& \sigma & \kappa \\
\mbox{Java} & 0.000011 & 0.006323 \\
\mbox{NodeJS} &  0.080319 & 0.000222 \\
\end{array}
\]

These systems scale very differently,\footnote{Both of them scale pretty poorly,
in fact.} and for very different reasons.  In a nutshell, the Java benchmark
shows much higher crosstalk penalty, whereas the NodeJS benchmark exhibits more
serialization. Examining the architectures of the two systems reveals why: the
Java app is multi-threaded and NodeJS is single-threaded with an event loop, and
the PayPal blog post even mentions that they used ``a single core for the
NodeJS application compared to five cores in Java.''

This is a great real-life example of key scalability tenets:

\begin{itemize}
\item Avoid serialization and make things as parallelizable as possible.
\item Avoid crosstalk and blocking or queueing.
\end{itemize}

\newpage

\section{Thinking Critically About The USL}

For many people, the USL is a huge shift in mindset. I know it was for me. But
is it the be-all and end-all? Of course not.

Not only is the USL unsuitable for solving every problem related to scalability
or capacity planning, sometimes it doesn't even work well for the problems it
{\itshape can} solve. The examples I've shown thus far are remarkable in that
they're extremely clean data. Real-world systems often have noisy data that
doesn't ``look like'' the USL much at all. It may look more like something your
cat threw up on the screen. Even when there is a nice-looking shape to the data,
regression can produce unphysical results, or refuse to produce results.

And then there are the systems for which you have nice clean-room measurements,
highly reproducible, but they just don't fit the USL very well. I could show
many examples. I've seen systems that appear to scale nicely, following the USL,
but suddenly flatline instead of continuing a graceful curve, or abruptly
degrade way faster than predicted---or the reverse, appearing to degrade more
{\itshape slowly} than predicted once we exit Amdahl territory and enter the
region where the higher-order terms prevail.  Here's an example:
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/handlersocket}
\end{center}

Maybe this is queue saturation or resource saturation, or maybe it's something
else, but the USL is unaware of it.

What, then, is the USL good for? The answer is lots.

First of all, a model is better than no model. In the absence of a model
explaining the workings of system scalability, there isn't even a point of
comparison to assess your expectations and results. There's no frame of
reference to say, ``I think this system should scale better than it does,'' or
``This system's behavior makes no sense.'' Whether the USL is applicable or not,
it still provides a framework. Without it, why not just draw lines at will? You
could get a set of French curves and draw curves as directed by your muse. No
one could say you're wrong.
\begin{center}
\includegraphics[width=.85\linewidth,trim={0 8cm 0 0},clip]{scalability/french_curve}
\end{center}

In an objective sense, the USL is incomplete or wrong, perhaps both. I don't
think it matters very much, but if it were complete and correct, it would
describe more systems and scenarios than it does in my experience. As Richard
Feynman said in a 1964 lecture at Cornell University, ``If it disagrees with
experiment, it’s wrong.  That simple statement is the key to science. It
doesn’t make a difference how beautiful your guess is, it doesn’t make a
difference how smart you are, who made the guess or what his name is---if it
disagrees with experiment, it’s wrong. That’s all there is to it.''

This is not to say the USL isn't useful. It's incredibly useful. But we must not
put it onto a pedestal and worship it.

I'd also like to note that one could quite easily conjecture and analyze other
USL-like models. For example, given that many computer algorithms can be shown
by analysis to be $\mathcal{O}(n\log{}n)$ instead of $\mathcal{O}(n^2)$, perhaps
we could assume that the quadratic $\kappa$ term doesn't really behave like its
worst-case, and the term could be replaced by a logarithmic term, like so?
\[
X(N) = \frac{\lambda N}{1 + \sigma(N-1) + \kappa \log(N)(N-1)}
\]

To give some visual intution of how this differs from the accepted form of the
USL, here they are together on a single plot. The standard USL is the solid line
and the logarithmic variant is the dashed line.
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/logscale}
\end{center}

You might think that you could choose parameters to the standard USL to make it
follow the dashed line better, but it doesn't work. The functions are of
different order and won't behave the same.

Would this be a better model for the data I showed previously? Visually, it does
appear to model the observed data somewhat more closely:
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/logscale-2}
\end{center}

Jayanta Choudhury has suggested changes to the USL to model cases such as this,
where resources apparently become saturated.  His 
Asymptotically Improved Super-Serial Law\footnote{See {\itshape Parameter
Estimation of Asymptotically Improved Super-serial Scalability Law} by Dr.
Jayanta Choudhury, of TeamQuest Corporation.} is slightly more complex:
\[
X(N) = \frac{\lambda N}{1 + \sigma(N-1) + \sigma \kappa N^\beta (N-1)}
\]

The $\beta$ parameter ranges from 0 to 1, inclusive. The following plot shows
the logarithmic variant I proposed in a solid line, and the AISSL in a dashed
line. As you can see, the logarithmic variation fits the data better.
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/aissl}
\end{center}

Unfortunately it's a bit difficult to estimate parameters for the AISSL, making
it harder to use than the USL. 

As I'm sure you can imagine, you could play games like this all day long.
Dreaming up an idea is much easier than proving that it's correct or showing
how it might arise analytically from the underlying mechanisms as we understand
them to operate in the system.

\section{Superlinear Scaling}

I've spent some time analyzing the possible causes of sublinear scaling. Is
superlinear scaling possible? As I've worked with the USL over the years, I've
found a number of cases where systems apparently do scale superlinearly. It
manifests as a negative $\sigma$ coefficient and a USL curve that has a more
complex shape, rising above linear and then below again:
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/superlinear}
\end{center}

At first I dismissed this result as unphysical (how can there be less than zero
contention?), but after repeatedly seeing this happen and having many
conversations with Neil Gunther about it, I started to wonder. So did he, and
eventually he was able to reproduce and explain the effect on a
\href{https://queue.acm.org/detail.cfm?id=2789974}{large-scale Hadoop TeraSort
benchmark}.

The TeraSort case is quite a specific one. In the more general case, I would
explain superlinear scalability as a disproportionate scaling of some resource
relative to the load placed upon it, creating an economy of scale. For example,
adding more nodes to a clustered database system adds more memory; if the
dataset size is not scaled proportionately, then more of the data fits into
memory on each node, and access times improve relative to disk reads. Any
resource that is more efficient when shared than when used singly may cause this
effect.

It's worth noting that this initial boost, depending upon its cause, may be
countered by a correspondingly disproportionate ``payback'' later when
performance falls quickly below linearity again.

Another special case to be aware of is that some clustered systems behave
differently at sizes 1 and 2 than they do at 3 and above. For example, at size 1
there is no crosstalk or contention---it isn't a distributed system. At size 2
special-cases may be in play. At size 3 and above, usually generic algorithms
and techniques suited for any size $n$ are in use. Some clustered systems have
to be benchmarked or measured at larger sizes in order to ignore these effects.

\section{Other Scalability Models}

In addition to the USL and the variants I've already discussed, there are many
other potential models of scalability you could consider. In my opinion some are
good, some are useful, some are not. I also believe that there is much more work
to be done on this topic.

Some alternative theories, however, are just garbage. Chief amongst them is
``quadratic scalability.'' Observing that systems under increasing amounts of
load will first increase in throughput, then level off and begin to decline,
some people get the bright idea that they should ``fit a curve to it.'' The curve
is always a quadratic polynomial and the fitted curve ends up being a parabola
opening downwards. Let's see how this looks on the benchmark data from Percona
once again:
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/quadratic}
\end{center}

Look, Ma, it's a great fit! I don't even need to compute the $R^2$ value to know
that. There's just one problem: it predicts that at some point we'll achieve
negative throughput.

You should ignore this model because by definition it doesn't work. Rather than
use it, I'd suggest that you get out that French curve set again and get in
touch with your inner artist.

A few other models that I've seen expressed in graphical form, but not
mathematically and lacking analysis, are:

\begin{itemize}
\item New Relic's scalability chart, which plots latency as a function of
throughput and renders a smoothed line through the points. The line has no
predetermined form and doesn't express any particular model.
\item AppDynamics's scalability analysis feature does the same thing, but fits a
parabola through the lines instead of a polynomial of arbitrarily high degree.
\item Cockcroft headroom plots, by Adrian Cockcroft. These are also
latency-versus-throughput charts, but add some histograms and other useful
visual cues around the edges.
\end{itemize}

These three express essentially the same belief about the relationship between
variables--that throughput is an independent variable and determines latency.
The differences between them are relatively minor. Here's an example of a
\href{http://perfcap.blogspot.nl/2008/07/enhanced-headroom-plot-in-r.html}{Cockcroft
Headroom Plot}:
\begin{center}
\includegraphics[width=.55\linewidth]{scalability/chpblog3}
\end{center}

The only trouble is, the assumption that latency is determined by throughput is
not correct in the general case. It may appear to be true as long as you don't
pass the point of maximum throughput and enter the territory of retrograde
scalability, but it's easy to see such a plot is not actually a function of
throughput after that happens:
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/not-a-function}
\end{center}

The reason for this is that once you enter retrograde scalability, throughput is
no longer under your control (e.g. you've saturated resources and you cannot
simply pick an arrival rate for requests and get the SUT to perform them for
you). In general, even in clean-room conditions, it is nearly impossible to
predictably drive a desired throughput for a system, unless you maintain a very
low utilization so requests don't queue. Throughput would only make sense as an
independent variable, in the general case, if it were under your direct control.
Therefore, latency as a function of throughput is probably not the way I would
choose to plot the data.\footnote{No, not even if
\href{http://perfdynamics.blogspot.nl/2015/07/hockey-elbow-and-other-response-time.html}{Neil Gunther does}.}

In fact, I think exactly the opposite is the correct relationship. Pick a
latency, and you can find the corresponding throughput at which that latency
will occur. Once again using the Percona benchmark data:
\begin{center}
\includegraphics[width=.85\linewidth]{scalability/latency-vs-throughput}
\end{center}

I'm leaving this as a reminder to myself to solve the USL for throughput as a
function of latency someday, using Little's Law. If you do it first, please
contact me and let me know.

\section{Hardware and Software Scalability}

I mentioned that Neil Gunther actually defines two forms of the USL, one for
hardware scaling and one for software. They're essentially the same equation,
with different Greek letters.

For most purposes it's not important to care about the distinction. However, it
is {\itshape very} important, in general, to have a firm grasp on the meaning of
the $X$ axis in the USL chart. I've been somewhat casual about it, essentially
treating it as a generic metric of size by which we scale the system or
workload, but I should be more precise.

In fact there are at least three important dimensions of the work a system
performs, and how it scales, and these three interact with each other. A correct
understanding of the concepts is important to get sensible results:

\begin{enumerate}
\item The number of things producing work requests for the
system. In a benchmark, for example, this is typically the configured
concurrency of the benchmark---that is, the number of driver threads. It could
also be the number of connections to the database, the number of users on a web
application, and so on.
\item The number of servers (as defined inqueueing theory). It could be the
number of CPUs in a server, the number of servers in a cluster, or the like.
\item The size of the dataset. This will most typically be in the usual
units---megabytes or gigabytes, number of rows---but will occasionally be the
number of logical partitions in the dataset (``shards''). A
\href{https://www.percona.com/blog/2011/02/28/is-voltdb-really-as-scalable-as-they-claim/}{VoltDB
benchmark} that I analyzed once needed to be couched in terms of partitions,
because of the configured per-partition redundancy.
\end{enumerate}

Now, what's really important to understand is that everything needs to be held
constant relative to the unit of scale you're using. If you're measuring
scalability at different cluster sizes, for example, you need to grow the number
of driver threads and the data size proportionately to the number of nodes in
the cluster, so each node receives the same amount and rate of work to perform
upon the same amount of data no matter the cluster size. (If you hold the
dataset constant and increase the number of nodes, you'll get superlinear
scalability.)

Other than this caveat, the Universal Scalability Law really is universal and is
a framework that can be applied to many different situations, as long as you can
define the variables correctly.

\section{Conclusions}



\section{Further Reading}

* GCaP
* Look at the Percona white paper
all of the books in my picture
missing: worst case usage, best case usage - compare to USL, why doesn't it
achieve at least this?
- everything you've learned applies to organizations and their communications
designs too.

\newpage

\begin{about}	% Build "About VividCortex"
VividCortex is a SaaS database performance monitoring platform. The database is the heart of most applications, but it's also the part that's hardest to scale, manage, and optimize even as it's growing 50\% year over year. VividCortex has developed a suite of unique technologies that significantly eases this pain for the entire IT department. Unlike traditional monitoring, we measure
and analyze the system's work and resource consumption. This leads directly to better performance for IT as a whole, at reduced cost and effort.
\end{about}
\makeresources	% Build "Related Resources"
\end{document}
